import * as vscode from "vscode";
import OpenAI from "openai";
import { getConfiguration } from "../config/config";
import { SupportedLanguage } from "../translationDatabase";
import { logMessage } from "../extension";
import * as path from "path";
import { AI_RETURN_CODE, getDiffSystemPrompt, getSystemPrompts } from "../config/prompt";
import { sanitizeUnexpectedCodeFences } from "./translationOutputSanitizer";
import { shouldWarnZeroEstimatedOutputTokens } from "./translationWarnings";
import { formatVendorHttpErrorForPopup } from "./vendorHttpError";
import { stripReasoningFromModelOutput } from "./translationReasoningStripper";
import { formatRawErrorForLog } from "./errorLog";
// no fs usage here

// Store the last request timestamp for each vendor
const vendorLastRequest: Map<string, number> = new Map();

// AI return codes are now imported from prompt.js

export interface TranslationProgressCallback {
  (chunk: string): void;
}

function extractTextFromMessageContent(messageContent: unknown): string {
  if (typeof messageContent === "string") {
    return messageContent;
  }
  // Some OpenAI-compatible vendors may return an array of content parts.
  if (Array.isArray(messageContent)) {
    return messageContent
      .map((p: any) => {
        if (!p) return "";
        if (typeof p === "string") return p;
        if (typeof p.text === "string") return p.text;
        if (typeof p.content === "string") return p.content;
        return "";
      })
      .join("");
  }
  return "";
}

function extractTextFromDeltaContent(deltaContent: unknown): string {
  if (typeof deltaContent === "string") {
    return deltaContent;
  }
  // Some vendors may stream content as an array of parts.
  if (Array.isArray(deltaContent)) {
    return deltaContent
      .map((p: any) => {
        if (!p) return "";
        if (typeof p === "string") return p;
        if (typeof p.text === "string") return p.text;
        if (typeof p.content === "string") return p.content;
        return "";
      })
      .join("");
  }
  return "";
}

type HiddenTagName = "think" | "analysis" | "reasoning" | null;

/**
 * è½»é‡çš„æµå¼è¿‡æ»¤å™¨ï¼šå»é™¤ <think>/<analysis>/<reasoning>...</...> å—å†…çš„å†…å®¹ï¼Œé¿å…å†™å…¥ç›®æ ‡æ–‡ä»¶ã€‚
 * è¯¥è¿‡æ»¤å™¨ä»…å¤„ç†è¿™äº›æ˜¾å¼æ ‡ç­¾ï¼›æ›´å¤æ‚çš„â€œæ€è€ƒ/ç¿»è¯‘â€æ ‡é¢˜å¼è¾“å‡ºåœ¨æœ€ç»ˆç»“æœé˜¶æ®µå†åšå‰¥ç¦»ã€‚
 */
class ReasoningTagStreamFilter {
  private inHidden: HiddenTagName = null;
  private carry = "";
  private readonly keepTail = 32;

  public process(input: string): string {
    if (!input) return "";
    let buf = this.carry + input;
    let out = "";
    this.carry = "";

    const openRe = /<\s*(think|analysis|reasoning)\s*>/i;
    const closeRe = (tag: string) => new RegExp(`<\\s*\\/\\s*${tag}\\s*>`, "i");

    // Bound the loop even on adversarial content.
    for (let guard = 0; guard < 10000 && buf.length > 0; guard++) {
      if (!this.inHidden) {
        const m = buf.match(openRe);
        if (!m || m.index === undefined) {
          if (buf.length <= this.keepTail) {
            this.carry = buf;
            break;
          }
          out += buf.slice(0, buf.length - this.keepTail);
          this.carry = buf.slice(buf.length - this.keepTail);
          break;
        }

        const idx = m.index;
        out += buf.slice(0, idx);
        const tag = String(m[1] || "").toLowerCase() as HiddenTagName;
        const endIdx = idx + m[0].length;
        buf = buf.slice(endIdx);
        this.inHidden = tag;
        continue;
      }

      // in hidden block: skip until matching close tag
      const tag = this.inHidden;
      if (!tag) {
        this.inHidden = null;
        continue;
      }
      const cRe = closeRe(tag);
      const mClose = buf.match(cRe);
      if (!mClose || mClose.index === undefined) {
        // Keep a small tail in case the close tag is split across chunks.
        if (buf.length > this.keepTail) {
          buf = buf.slice(buf.length - this.keepTail);
        }
        this.carry = buf;
        break;
      }
      const endIdx = mClose.index + mClose[0].length;
      buf = buf.slice(endIdx);
      this.inHidden = null;
    }

    return out;
  }

  public flush(): string {
    const tail = this.carry;
    this.carry = "";
    // If we ended while "inHidden", dropping the tail is safer than leaking reasoning.
    if (this.inHidden) {
      return "";
    }
    return tail;
  }
}

function isOpenRouterSseCommentLine(line: string): boolean {
  // OpenRouter SSE comments look like: ": OPENROUTER PROCESSING"
  // We only filter these very specific lines to avoid corrupting legitimate content.
  return /^\s*:\s*OPENROUTER\b/i.test(line);
}

function safeStringifyForLog(x: unknown): string {
  if (typeof x === "string") return x;
  try {
    return JSON.stringify(x);
  } catch {
    return String(x);
  }
}

export class TranslatorService {
  private openaiClient: OpenAI | null = null;
  private outputChannel: vscode.OutputChannel;
  private projectTotalInputTokens = 0;
  private projectTotalOutputTokens = 0;
  private workspaceRoot: string | null = null;
  private shownVendorHttpErrorKeys: Set<string> = new Set();

  constructor(outputChannel: vscode.OutputChannel) {
    this.outputChannel = outputChannel;
    // Get workspace root for saving diff responses
    const workspaceFolders = vscode.workspace.workspaceFolders;
    if (workspaceFolders && workspaceFolders.length > 0) {
      this.workspaceRoot = workspaceFolders[0].uri.fsPath;
    }
  }

  public async initializeOpenAIClient() {
    const { currentVendor } = await getConfiguration();
    const { apiEndpoint, apiKey, apiKeyEnvVarName, model, timeout } = currentVendor;
    
    let finalApiKey = apiKey;
    if (!finalApiKey && apiKeyEnvVarName) {
      finalApiKey = process.env[apiKeyEnvVarName];
      if (finalApiKey) {
        logMessage(
          `ğŸ”‘ Using API key from environment variable: ${apiKeyEnvVarName}`
        );
      }
    }
    
    if (!finalApiKey) {
      logMessage(
        "âŒ API key is not set in the vendor configuration or environment variable",
        "error"
      );
      throw new Error("API key is not set in the vendor configuration or environment variable");
    }
    
    if (!apiEndpoint) {
      logMessage(
        "âŒ API endpoint is not set in the vendor configuration",
        "error"
      );
      throw new Error("API endpoint is not set in the vendor configuration");
    }
    if (!model) {
      logMessage(
        "âŒ Model is not set in the vendor configuration",
        "error"
      );
      throw new Error("Model is not set in the vendor configuration");
    }

    logMessage(
      `ğŸ”‘ Using vendor API endpoint: ${apiEndpoint}`
    );
    const config: ConstructorParameters<typeof OpenAI>[0] = {
      apiKey: finalApiKey,
      baseURL: apiEndpoint,
    };

    const timeoutMs = timeout ? timeout * 1000 : 300000;
    logMessage(
      `â±ï¸ API request timeout setting: ${
        timeout || 180
      } seconds (${timeoutMs}ms)`
    );
    config.timeout = timeoutMs;

    this.openaiClient = new OpenAI(config);
  }

  /**
   * è§£æAIè¿”å›çš„æ— éœ€ç¿»è¯‘å“åº”
   * æ–°æ ¼å¼: "ç†ç”± | UUID"
   * æ—§æ ¼å¼: "UUID" (å‘åå…¼å®¹)
   * @returns è¿”å›å¯¹è±¡ { hasReason: boolean, reason?: string }
   */
  private parseNoNeedTranslateResponse(content: string): { hasReason: boolean; reason?: string } {
    const delimiter = " | ";
    if (content.includes(delimiter)) {
      const parts = content.split(delimiter);
      if (parts.length >= 2) {
        // æ£€æŸ¥æœ€åä¸€éƒ¨åˆ†æ˜¯å¦åŒ…å«UUID
        const lastPart = parts[parts.length - 1].trim();
        if (lastPart.includes(AI_RETURN_CODE.NO_NEED_TRANSLATE)) {
          // æ ¼å¼: ç†ç”± | UUID
          const reason = parts.slice(0, -1).join(delimiter).trim();
          return { hasReason: true, reason };
        }
      }
    }
    return { hasReason: false };
  }

  public async translateContent(
    content: string,
    sourceLang: SupportedLanguage,
    targetLang: SupportedLanguage,
    sourcePath: string,
    cancellationToken?: vscode.CancellationToken,
    progressCallback?: TranslationProgressCallback,
    isFirstSegment: boolean = true // Add parameter to indicate if this is the first segment
  ): Promise<[string, string]> {
    if (!this.openaiClient) {
      const error = "OpenAI client not initialized";
      logMessage(`âŒ ${error}`, "error");
      throw new Error(error);
    }

    const config = await getConfiguration();
    const { currentVendorName, currentVendor, customPrompts } = config;
    const debug = !!config.debug;
    // Ensure temperature has a sensible default if undefined
    const { model, rpm, streamMode } = currentVendor;
    const temperature = currentVendor.temperature === undefined ? 0.1 : currentVendor.temperature;
    const vendorTimeoutSeconds = currentVendor.timeout === undefined ? 180 : currentVendor.timeout;
    const streamIdleTimeoutMs = Math.max(1000, vendorTimeoutSeconds * 1000);

    logMessage(`ğŸ¤– Using model: ${model}`);
    logMessage(`ğŸŒ Target language: ${targetLang}`);
    logMessage(`ğŸ² Temperature: ${temperature}`);

    if (streamMode) {
      logMessage(`ğŸ”„ Stream mode enabled`);
    } // Wait for RPM limit if needed
    if (rpm && rpm > 0) {
      await this.handleRpmLimit(currentVendorName, rpm, cancellationToken);
    }

	    // Prepare system prompts based on whether this is the first segment
	    const { part1, part2, customPromptSectionTitle } = getSystemPrompts(
	      config.systemPromptLanguage
	    );
	    let effectiveSystemPrompts: string[];
	    if (isFirstSegment) {
	      // For the first segment, use both parts of the default system prompt
	      effectiveSystemPrompts = [part1, part2];
	    } else {
	      // For subsequent segments, use only the first part
	      effectiveSystemPrompts = [part1];
	    }

    // Merge default system prompts with user custom prompts
    let mergedSystemPrompt = effectiveSystemPrompts.join("\n");

	    // Append user custom prompts to system prompt
	    if (customPrompts && customPrompts.length > 0) {
	      mergedSystemPrompt += `\n\n${customPromptSectionTitle}\n\n`;
	      mergedSystemPrompt += customPrompts.join("\n\n");
	    }

    // Message ordering per requirement:
    // 1) system: default system prompts + custom prompts
    // 2) user: raw content
    // 3) user: built-in translation prompt
    const messages: Array<{ role: string; content: string }> = [
      {
        role: "system",
        content: mergedSystemPrompt,
      },
      {
        role: "user",
        content: content,
      },
      {
        role: "user",
        content: `Please translate the preceding content from ${sourceLang} to ${targetLang}.`,
      },
    ];

    try {
      logMessage("ğŸ“¤ Sending translation request...");

      // Use stream mode if enabled and progressCallback is provided
      if (streamMode && progressCallback) {
        return await this.streamTranslateContent(
          messages,
          model || "",
          temperature,
          currentVendorName,
          content,
          progressCallback,
          cancellationToken,
          debug,
          currentVendor.top_p,
          sourcePath,
          streamIdleTimeoutMs
        );
      } else {
        return await this.standardTranslateContent(
          messages,
          model || "",
          temperature,
          currentVendorName,
          content,
          debug,
          currentVendor.top_p,
          sourcePath
        );
      }
    } catch (error) {
      // æ‰“å°åŸå§‹é”™è¯¯ï¼ˆå« stack/causeï¼‰ï¼Œä¾¿äºæ’æŸ¥è¯¸å¦‚ "Premature close" è¿™ç±»åº•å±‚è¿æ¥é”™è¯¯
      logMessage(`âŒ [RAW ERROR] ${formatRawErrorForLog(error)}`, "error");

      const popup = formatVendorHttpErrorForPopup(error, {
        vendorName: currentVendorName,
        model,
        sourcePath,
        operation: "translate",
      });
      if (popup && !this.shownVendorHttpErrorKeys.has(popup.key)) {
        this.shownVendorHttpErrorKeys.add(popup.key);
        vscode.window.showErrorMessage(popup.message);
      }

      const errorMessage =
        error instanceof Error ? error.message : "Unknown error";
      logMessage(`âŒ Translation failed: ${errorMessage}`, "error");
      throw error;
    }
  }

  /**
   * ç”Ÿæˆ Roo-Code é£æ ¼çš„ SEARCH/REPLACE å·®å¼‚å—
   * è¦æ±‚æ¨¡å‹ä¸¥æ ¼è¾“å‡ºç”±å¤šä¸ª SEARCH/REPLACE å—ç»„æˆçš„çº¯æ–‡æœ¬ï¼Œä¸å¾—åŒ…å«å›´æ æˆ–è§£é‡Š
   */
  public async generateSearchReplaceDiff(
    sourceContent: string,
    targetContent: string,
    sourcePath: string,
    sourceLang: SupportedLanguage,
    targetLang: SupportedLanguage
  ): Promise<string> {
    if (!this.openaiClient) {
      const error = "OpenAI client not initialized";
      logMessage(`âŒ ${error}`, "error");
      throw new Error(error);
    }

	    const config = await getConfiguration();
	    const { currentVendorName, currentVendor, customPrompts } = config;
	    const {
	      part1,
	      part2,
	      diffSystemPrompt,
	      customPromptSectionTitle,
	    } = getSystemPrompts(config.systemPromptLanguage);

	    // Build system prompt with default prompts and diff prompt
	    let mergedSystemPrompt = [
	      part1,
	      part2,
	      diffSystemPrompt
	    ].join("\n");

	    // Append user custom prompts to system prompt
	    if (customPrompts && customPrompts.length > 0) {
	      mergedSystemPrompt += `\n\n${customPromptSectionTitle}\n\n`;
	      mergedSystemPrompt += customPrompts.join("\n\n");
	    }

    const messages: Array<{ role: string; content: string }> = [
      { role: "system", content: mergedSystemPrompt },
	      {
	        role: "system",
	        content: getDiffSystemPrompt(
	          sourceLang,
	          targetLang,
	          sourcePath,
	          config.systemPromptLanguage
	        ),
	      },
      // å…ˆæä¾› SOURCE åæä¾› TARGETï¼Œä¾¿äºæ¨¡å‹å¯¹é½
      { role: "user", content: `SOURCE BEGIN\n${sourceContent}\nSOURCE END` },
      { role: "user", content: `TARGET BEGIN\n${targetContent}\nTARGET END` }
    ];

    logMessage(`ğŸ”„ Sending differential translation request...`);
    logMessage(`ğŸ”„ Messages: ${JSON.stringify(messages, null, 2)}`);

    const payload: OpenAI.ChatCompletionCreateParamsNonStreaming = {
      model: currentVendor.model,
      messages: messages as OpenAI.ChatCompletionMessageParam[],
      temperature: currentVendor.temperature,
      top_p: currentVendor.top_p,
      response_format: { type: "json_object" },
    };

    let response: OpenAI.ChatCompletion;
    try {
      response = await this.openaiClient.chat.completions.create(payload);
    } catch (error) {
      logMessage(`âŒ [RAW ERROR] ${formatRawErrorForLog(error)}`, "error");
      const popup = formatVendorHttpErrorForPopup(error, {
        vendorName: currentVendorName,
        model: currentVendor.model,
        sourcePath,
        operation: "diff",
      });
      if (popup && !this.shownVendorHttpErrorKeys.has(popup.key)) {
        this.shownVendorHttpErrorKeys.add(popup.key);
        vscode.window.showErrorMessage(popup.message);
      }
      throw error;
    }
    vendorLastRequest.set(currentVendorName, Date.now());
    const content = response.choices?.[0]?.message?.content?.trim() || '';

    // Parse JSON response and convert to SEARCH/REPLACE format
    try {
      const diffResult = JSON.parse(content) as {
        has_changes: boolean;
        changes: Array<{ start_line: number; search: string; replace: string }>;
      };

      if (!diffResult.has_changes || !diffResult.changes || diffResult.changes.length === 0) {
        logMessage("â„¹ï¸ No changes detected in diff");
        return "";
      }

      // Convert JSON to SEARCH/REPLACE format
      const searchReplaceBlocks = diffResult.changes.map((change) => {
        return `<<<<<<< SEARCH
:start_line: ${change.start_line}
-------
${change.search}
=======
${change.replace}
>>>>>>> REPLACE`;
      }).join("\n\n");

      logMessage(`âœ… Converted JSON diff to SEARCH/REPLACE format (${diffResult.changes.length} blocks)`);
      return searchReplaceBlocks;
    } catch (e) {
      logMessage(`âŒ Failed to parse JSON diff response: ${e instanceof Error ? e.message : String(e)}`, "error");
      logMessage(`ğŸ“„ Raw response: ${content}`);
      throw new Error(`Failed to parse JSON diff response: ${e instanceof Error ? e.message : String(e)}`);
    }
  }

  private async standardTranslateContent(
    messages: Array<{ role: string; content: string }>,
    model: string,
    temperature: number | undefined,
    currentVendorName: string,
    originalContent: string,
    debug: boolean | undefined,
    topP: number | undefined,
    sourcePath: string = ""
  ): Promise<[string, string]> {
    if (!this.openaiClient) {
      throw new Error("OpenAI client not initialized");
    }

    // Record start time for API request
    const startTime = Date.now();
    logMessage(`â±ï¸ Starting OpenAI API request at ${new Date(startTime).toISOString()}`);

    const requestPayload: any = {
      model: model,
      messages: messages as OpenAI.ChatCompletionMessageParam[],
      temperature: temperature,
    };

    // Add top_p to request if it's set
    if (topP !== undefined) {
      requestPayload.top_p = topP;
    }

    // Debug: Log request payload
    if (debug) {
      logMessage(`ğŸ› [DEBUG] OpenAI API Request:`);
      logMessage(`ğŸ› [DEBUG] ${JSON.stringify(requestPayload, null, 2)}`);
    }

    const response = await this.openaiClient.chat.completions.create(requestPayload);

    // Record end time and calculate duration
    const endTime = Date.now();
    const duration = endTime - startTime;
    logMessage(`â±ï¸ OpenAI API request completed in ${duration}ms (${(duration / 1000).toFixed(2)}s)`);

    // Debug: Log response
    if (debug) {
      logMessage(`ğŸ› [DEBUG] OpenAI API Response:`);
      logMessage(`ğŸ› [DEBUG] ${JSON.stringify(response, null, 2)}`);
    }

    // Update the timestamp regardless of translation status
    vendorLastRequest.set(currentVendorName, Date.now());

    const inputTokens = response.usage?.prompt_tokens || 0;
    const outputTokens = response.usage?.completion_tokens || 0;
    logMessage(
      `ğŸ“¥ Translation request completed (input: ${inputTokens} tokens, output: ${outputTokens} tokens)`
    );

    this.projectTotalInputTokens += inputTokens;
    this.projectTotalOutputTokens += outputTokens;

    const translatedContent =
      extractTextFromMessageContent((response.choices as any)?.[0]?.message?.content) || originalContent;

    // å…ˆç”¨ raw å†…å®¹åˆ¤æ–­ NO_NEED_TRANSLATEï¼ˆå³ä½¿å®ƒå‡ºç°åœ¨æ€è€ƒå—é‡Œä¹Ÿåº”å‘½ä¸­ï¼‰ã€‚
    if (translatedContent.includes(AI_RETURN_CODE.NO_NEED_TRANSLATE)) {
      const parsed = this.parseNoNeedTranslateResponse(translatedContent);
      if (parsed.hasReason) {
        logMessage(
          `ğŸ”„ AI indicated no translation needed for this file. Reason: ${parsed.reason}`
        );
      } else {
        logMessage(
          `ğŸ”„ AI indicated no translation needed for this file, skipping translation`
        );
      }
      return [AI_RETURN_CODE.NO_NEED_TRANSLATE, originalContent]; // Return the original content unchanged
    }

    const stripped = stripReasoningFromModelOutput(translatedContent);
    if (debug && stripped.didStrip) {
      logMessage(`ğŸ› [DEBUG] Stripped reasoning/thinking from translation response`);
    }
    const candidate = stripped.text;

    const sanitizedContent = sanitizeUnexpectedCodeFences(originalContent, candidate);
    if (debug && sanitizedContent !== candidate) {
      logMessage(`ğŸ› [DEBUG] Stripped unexpected code fences from translation response`);
    }

    return [AI_RETURN_CODE.OK, sanitizedContent];
  }

  private async streamTranslateContent(
    messages: Array<{ role: string; content: string }>,
    model: string,
    temperature: number | undefined,
    currentVendorName: string,
    originalContent: string,
    progressCallback: TranslationProgressCallback,
    cancellationToken?: vscode.CancellationToken,
    debug: boolean | undefined = false,
    topP: number | undefined = undefined,
    sourcePath: string = "",
    streamIdleTimeoutMs: number = 180000
  ): Promise<[string, string]> {
    if (!this.openaiClient) {
      throw new Error("OpenAI client not initialized");
    }

    logMessage(`ğŸ”„ Starting streaming translation...`);
    const reasoningFilter = new ReasoningTagStreamFilter();
    let fullContent = ""; // filtered translation-only stream
    let rawAssistantContent = ""; // raw delta.content/text (may include think tags)
    let rawReasoningContent = ""; // delta.reasoning_content/thinking (should not be written to file)
    let sawAnyDeltaContent = false;
    let reasoningOnlyBuffer = ""; // æŸäº›ä¾›åº”å•†ä¼šæŠŠâ€œæœ€ç»ˆè¾“å‡ºâ€é”™è¯¯åœ°æ”¾åœ¨ delta.reasoning é‡Œï¼Œå…ˆç¼“å†²ï¼Œè‹¥åç»­å‡ºç° content åˆ™ä¸¢å¼ƒ
    let foundNoNeedTranslate = false;

    // Extract the first part of the UUID to detect partial occurrences
    const uuidFirstPart = AI_RETURN_CODE.NO_NEED_TRANSLATE.substring(0, 20);

    // Record start time for streaming API request
    const startTime = Date.now();
    logMessage(`â±ï¸ Starting OpenAI streaming API request at ${new Date(startTime).toISOString()}`);

    const requestPayload: any = {
      model: model,
      messages: messages as OpenAI.ChatCompletionMessageParam[],
      temperature: temperature,
      stream: true,
    };

    // Add top_p to request if it's set
    if (topP !== undefined) {
      requestPayload.top_p = topP;
    }

    // Debug: Log request payload
    if (debug) {
      logMessage(`ğŸ› [DEBUG] OpenAI Streaming API Request:`);
      logMessage(`ğŸ› [DEBUG] ${JSON.stringify(requestPayload, null, 2)}`);
    }

    const abortController = new (globalThis as any).AbortController();
    let inactivityAbortReason: Error | null = null;
    let idleTimer: NodeJS.Timeout | null = null;
    let lastMessageAt = Date.now();
    const armIdleTimer = () => {
      lastMessageAt = Date.now();
      if (idleTimer) {
        globalThis.clearTimeout(idleTimer as any);
      }
      idleTimer = globalThis.setTimeout(() => {
        const now = Date.now();
        const idleForMs = now - lastMessageAt;
        inactivityAbortReason = new Error(
          `æµå¼ä¼ è¾“è¶…æ—¶ï¼šè·ç¦»ä¸Šä¸€æ¡ stream æ¶ˆæ¯å·²è¿‡å» ${idleForMs}msï¼ˆè®¾ç½® timeout=${streamIdleTimeoutMs}msï¼‰ï¼Œç»ˆæ­¢å½“å‰æ–‡ä»¶ç¿»è¯‘ï¼š${sourcePath || "(unknown sourcePath)"}`
        );
        try {
          abortController.abort();
        } catch {
          // ignore
        }
      }, streamIdleTimeoutMs) as any;
    };
    armIdleTimer();

    const stream = await (this.openaiClient.chat.completions.create(
      requestPayload,
      { signal: abortController.signal } as any
    ) as any);

    // Update request timestamp at the start of streaming
    vendorLastRequest.set(currentVendorName, Date.now());

    // Initialize token counters - this is an estimate since the streaming API doesn't provide token counts
    let estimatedInputTokens = 0;
    let estimatedOutputTokens = 0;

    let ignoredMalformedChunkCount = 0;
    const warnIgnoredMalformedChunk = (reason: string, detail?: string) => {
      ignoredMalformedChunkCount++;
      // é˜²æ­¢ Output Channel è¢«åˆ·å±ï¼šåªå¯¹å‰å‡ æ¡å’Œä¹‹åçš„å‘¨æœŸæ€§æ¡ç›®è¾“å‡º warn
      const shouldWarn =
        ignoredMalformedChunkCount <= 5 || ignoredMalformedChunkCount % 200 === 0;
      if (!shouldWarn) {
        return;
      }
      const trimmed =
        detail && detail.length > 240 ? `${detail.slice(0, 240)}â€¦` : detail;
      logMessage(
        `âš ï¸ [stream] å·²å¿½ç•¥ä¸ç¬¦åˆæ•°æ®ç»“æ„çš„æ¶ˆæ¯ï¼ˆ${reason}ï¼‰${
          trimmed ? `: ${trimmed}` : ""
        }`,
        "warn"
      );
    };

    let lastFinishReason: string | null = null;
    let lastNativeFinishReason: string | null = null;

    // Estimate input tokens based on input messages
    for (const message of messages) {
      // Rough estimate: 1 token â‰ˆ 4 characters for English
      estimatedInputTokens += Math.ceil(message.content.length / 4);
    }

    try {
      for await (const chunk of stream) {
      if (cancellationToken?.isCancellationRequested) {
        logMessage("â›” Translation cancelled", "warn");
        throw new vscode.CancellationError();
      }

      // æ”¶åˆ°ä»»ä½• chunkï¼ˆåŒ…å«å°†è¢«å¿½ç•¥çš„å¼‚å¸¸ç»“æ„ï¼‰éƒ½è§†ä¸ºâ€œæµä»åœ¨æ´»è·ƒâ€ï¼Œé‡ç½® idle è¶…æ—¶è®¡æ—¶å™¨
      armIdleTimer();

      // ç”¨æˆ·å¼€å¯ debug æ—¶ï¼Œè¦æ±‚å°†æ‰€æœ‰æµå¼è¿”å›æ¶ˆæ¯åŸæ ·è¾“å‡ºï¼ˆåŒ…æ‹¬å°†è¢«å¿½ç•¥çš„æ³¨é‡Šè¡Œ/å¼‚å¸¸ç»“æ„ï¼‰ã€‚
      if (debug) {
        logMessage(`ğŸ› [DEBUG] [stream] RAW: ${safeStringifyForLog(chunk)}`);
      }

      // OpenRouter streaming is SSE and may include comment lines like ": OPENROUTER PROCESSING".
      // These lines are not JSON/data events and must be ignored without breaking the stream.
      if (typeof chunk === "string") {
        if (isOpenRouterSseCommentLine(chunk)) {
          warnIgnoredMalformedChunk("OpenRouter SSE comment line", chunk);
          continue;
        }
        // Unknown raw line: ignore but keep a breadcrumb in debug.
        warnIgnoredMalformedChunk("non-JSON stream line", chunk);
        continue;
      }

      // Some OpenAI-compatible SDKs may yield non-standard objects/events; ignore them safely.
      if (!chunk || typeof chunk !== "object") {
        warnIgnoredMalformedChunk("non-object chunk", String(chunk));
        continue;
      }

      const choices: any[] | undefined = (chunk as any).choices;
      if (!Array.isArray(choices) || choices.length === 0) {
        warnIgnoredMalformedChunk(
          "chunk without choices",
          JSON.stringify(chunk)
        );
        continue;
      }

      // Track finish reasons if provided by vendor (useful for diagnosing "why stream ended").
      const finishReason = typeof choices[0]?.finish_reason === "string" ? choices[0].finish_reason : null;
      const nativeFinishReason = typeof choices[0]?.native_finish_reason === "string" ? choices[0].native_finish_reason : null;
      if (finishReason) {
        lastFinishReason = finishReason;
      }
      if (nativeFinishReason) {
        lastNativeFinishReason = nativeFinishReason;
      }

      const delta: any = choices[0]?.delta;
      if (!delta || typeof delta !== "object") {
        warnIgnoredMalformedChunk("chunk without delta", JSON.stringify(chunk));
        continue;
      }

      let deltaContent =
        extractTextFromDeltaContent(delta?.content) ||
        (typeof delta?.text === "string" ? delta.text : "");
      const deltaReasoningFromDetails = Array.isArray(delta?.reasoning_details)
        ? delta.reasoning_details
            .map((d: any) => (typeof d?.text === "string" ? d.text : ""))
            .join("")
        : "";
      const deltaReasoning =
        (typeof delta?.reasoning_content === "string" ? delta.reasoning_content : "") ||
        (typeof delta?.thinking === "string" ? delta.thinking : "") ||
        (typeof delta?.reasoning === "string" ? delta.reasoning : "") ||
        deltaReasoningFromDetails;

      if (deltaContent && isOpenRouterSseCommentLine(deltaContent)) {
        warnIgnoredMalformedChunk(
          "OpenRouter comment inside delta.content",
          deltaContent
        );
        deltaContent = "";
      }

      if (debug) {
        if (deltaReasoning) {
          logMessage(`ğŸ› [DEBUG] [stream] delta.reasoning_content: ${deltaReasoning}`);
        }
        if (deltaContent) {
          logMessage(`ğŸ› [DEBUG] [stream] delta.content: ${deltaContent}`);
        }
      }

      if (deltaReasoning) {
        rawReasoningContent += deltaReasoning;
        // åœ¨æœªçœ‹åˆ°ä»»ä½• delta.content çš„æƒ…å†µä¸‹ï¼Œå…ˆç¼“å†² reasoningï¼ˆå¯èƒ½æ˜¯ä¾›åº”å•†æŠŠæœ€ç»ˆè¾“å‡ºæ”¾é”™å­—æ®µï¼‰
        if (!sawAnyDeltaContent) {
          reasoningOnlyBuffer += deltaReasoning;
        }
        const combinedAfterReasoning = rawAssistantContent + rawReasoningContent;
        if (
          !foundNoNeedTranslate &&
          (combinedAfterReasoning.includes(AI_RETURN_CODE.NO_NEED_TRANSLATE) ||
            combinedAfterReasoning.includes(uuidFirstPart))
        ) {
          foundNoNeedTranslate = true;
          logMessage(`ğŸ”„ AI indicated no translation needed (in stream)`);
          break;
        }
      }

      if (deltaContent) {
        sawAnyDeltaContent = true;
        reasoningOnlyBuffer = ""; // æ—¢ç„¶åç»­å‡ºç°äº†çœŸå® contentï¼Œåˆ™ä¸¢å¼ƒä¹‹å‰ç¼“å†²çš„ reasoningï¼Œé¿å…æ··å…¥æ€è€ƒå†…å®¹
        // If this chunk contains the special code or a fragment, only stream the safe prefix.
        const fullCodeIndex = deltaContent.indexOf(AI_RETURN_CODE.NO_NEED_TRANSLATE);
        const partialCodeIndex = deltaContent.indexOf(uuidFirstPart);
        const indexToUse =
          fullCodeIndex >= 0 && partialCodeIndex >= 0
            ? Math.min(fullCodeIndex, partialCodeIndex)
            : fullCodeIndex >= 0
              ? fullCodeIndex
              : partialCodeIndex;

        const toProcess = indexToUse >= 0 ? deltaContent.slice(0, indexToUse) : deltaContent;
        rawAssistantContent += deltaContent;
        const filtered = reasoningFilter.process(toProcess);
        if (filtered) {
          fullContent += filtered;

          // Only send content to progress callback if we're not in foundNoNeedTranslate state
          progressCallback(filtered);
        }

        if (indexToUse >= 0) {
          foundNoNeedTranslate = true;
          logMessage(`ğŸ”„ AI indicated no translation needed (in chunk)`);
          break;
        }

        // Rough estimate: 1 token â‰ˆ 4 characters for English
        estimatedOutputTokens += Math.ceil(deltaContent.length / 4);
      }

      // Handle partial UUID occurrences that are split across chunks.
      if (!foundNoNeedTranslate) {
        const combinedSoFar = rawAssistantContent + rawReasoningContent;
        if (
          combinedSoFar.includes(AI_RETURN_CODE.NO_NEED_TRANSLATE) ||
          combinedSoFar.includes(uuidFirstPart)
        ) {
          foundNoNeedTranslate = true;
          logMessage(`ğŸ”„ AI indicated no translation needed (in stream)`);
          break;
        }
      }
      }
    } catch (err) {
      if (inactivityAbortReason) {
        // è®°å½•äº‹å®ï¼šè§¦å‘çš„æ˜¯â€œæ— æ¶ˆæ¯è¶…æ—¶â€ï¼Œä¸æ˜¯çŒœæµ‹
        logMessage(`âŒ ${inactivityAbortReason.message}`, "error");
        throw inactivityAbortReason;
      }
      throw err;
    } finally {
      if (idleTimer) {
        globalThis.clearTimeout(idleTimer as any);
      }
    }

    // Flush any remaining tail (if not inside a reasoning block).
    if (!foundNoNeedTranslate) {
      const flushed = reasoningFilter.flush();
      if (flushed) {
        fullContent += flushed;
        progressCallback(flushed);
        estimatedOutputTokens += Math.ceil(flushed.length / 4);
      }
    }

    // Record end time and calculate duration for streaming
    const endTime = Date.now();
    const duration = endTime - startTime;
    const shouldZeroOutputWarn = shouldWarnZeroEstimatedOutputTokens({
      estimatedOutputTokens,
      foundNoNeedTranslate,
      originalContent,
    });
    if (shouldZeroOutputWarn) {
      const facts: string[] = [];
      if (lastFinishReason) {
        facts.push(`finish_reason=${lastFinishReason}`);
      }
      if (lastNativeFinishReason && lastNativeFinishReason !== lastFinishReason) {
        facts.push(`native_finish_reason=${lastNativeFinishReason}`);
      }
      if (!sawAnyDeltaContent) {
        facts.push("æœªæ”¶åˆ°ä»»ä½•éç©º delta.content");
      }
      if (rawReasoningContent.trim().length > 0) {
        facts.push(`æ”¶åˆ° delta.reasoning*ï¼ˆ${rawReasoningContent.length} charsï¼‰`);
      }
      if (ignoredMalformedChunkCount > 0) {
        facts.push(`å¿½ç•¥å¼‚å¸¸æ¶ˆæ¯=${ignoredMalformedChunkCount}`);
      }

      const reason = facts.length > 0 ? facts.join("ï¼›") : "æœªè§£æåˆ°å¯è®¡å…¥è¾“å‡ºçš„æµå¼æ–‡æœ¬åˆ†ç‰‡";
      logMessage(
        `âš ï¸ Streaming estimated output: ~0 tokensã€‚åŸå› ï¼š${reason}ã€‚` +
          (debug ? "ï¼ˆdebug å·²å¼€å¯ï¼Œå¯æŸ¥çœ‹ä¸Šæ–¹ [DEBUG] [stream] RAW/deltaï¼‰" : ""),
        "warn"
      );
    }
    logMessage(
      `ğŸ“¥ Streaming translation completed in ${duration}ms (${(duration / 1000).toFixed(2)}s) (estimated input: ~${estimatedInputTokens} tokens, estimated output: ~${estimatedOutputTokens} tokens)`
    );
    logMessage(`â±ï¸ OpenAI streaming API request total duration: ${duration}ms`);

    if (ignoredMalformedChunkCount > 5) {
      logMessage(
        `âš ï¸ [stream] æœ¬æ¬¡æµå¼è¯·æ±‚å…±å¿½ç•¥äº† ${ignoredMalformedChunkCount} æ¡ä¸ç¬¦åˆæ•°æ®ç»“æ„çš„æ¶ˆæ¯ï¼ˆä¸ºé¿å…åˆ·å±ï¼Œä»…å±•ç¤ºéƒ¨åˆ† warnï¼‰ã€‚`,
        "warn"
      );
    }

    // Decide the final candidate:
    // - Prefer raw assistant content (delta.content/text) with reasoning stripped.
    // - Fallback to filtered streamed content (fullContent).
    // - As a last resort, if vendor put text into reasoning_content, use it to avoid empty target files.
    const stripped = stripReasoningFromModelOutput(rawAssistantContent);
    if (debug && stripped.didStrip) {
      logMessage(`ğŸ› [DEBUG] Stripped reasoning/thinking from streaming translation response`);
    }
    let candidate = stripped.text;
    if (candidate.trim().length === 0 && fullContent.trim().length > 0) {
      candidate = fullContent;
    }
    if (candidate.trim().length === 0 && rawReasoningContent.trim().length > 0) {
      logMessage(
        `âš ï¸ Streaming response had empty delta.content; falling back to delta.reasoning* fields to avoid empty translation output. This usually indicates a vendor/model streaming incompatibility.`,
        "warn"
      );
      // ä¼˜å…ˆä½¿ç”¨ reasoningOnlyBufferï¼ˆä»…åœ¨ä»æœªå‡ºç°è¿‡ delta.content æ—¶æ‰ç´¯è®¡ï¼‰ï¼Œé¿å…â€œå…ˆæ€è€ƒåè¾“å‡ºâ€çš„åœºæ™¯è¯¯æ··å…¥
      const reasoningToUse =
        !sawAnyDeltaContent && reasoningOnlyBuffer.trim().length > 0
          ? reasoningOnlyBuffer
          : rawReasoningContent;
      if (!sawAnyDeltaContent && reasoningOnlyBuffer.trim().length > 0) {
        logMessage(
          `âš ï¸ [stream] delta.content å§‹ç»ˆä¸ºç©ºï¼›å°†ä½¿ç”¨ delta.reasoning ä½œä¸ºè¾“å‡ºå†…å®¹ï¼ˆè¯·è€ƒè™‘æ›´æ¢æ¨¡å‹æˆ–å…³é—­ reasoning è¾“å‡ºä»¥è·å¾—æ›´ç¨³å®šçš„æµå¼ contentï¼‰ã€‚`,
          "warn"
        );
      }
      const strippedReasoning = stripReasoningFromModelOutput(reasoningToUse);
      candidate =
        strippedReasoning.text.trim().length > 0
          ? strippedReasoning.text
          : reasoningToUse;
    }

    const sanitizedFullContent = sanitizeUnexpectedCodeFences(originalContent, candidate);
    if (debug && sanitizedFullContent !== candidate) {
      logMessage(`ğŸ› [DEBUG] Stripped unexpected code fences from streaming translation response`);
    }

    // Debug: Log complete streaming response
    if (debug) {
      logMessage(`ğŸ› [DEBUG] Complete Streaming Response Content:`);
      logMessage(`ğŸ› [DEBUG] ${sanitizedFullContent}`);
    }

    // Add estimated tokens to project total
    this.projectTotalInputTokens += estimatedInputTokens;
    this.projectTotalOutputTokens += estimatedOutputTokens;



    // Check if the response contains the full or partial UUID code
    if (
      foundNoNeedTranslate ||
      (rawAssistantContent + rawReasoningContent).includes(AI_RETURN_CODE.NO_NEED_TRANSLATE) ||
      (rawAssistantContent + rawReasoningContent).includes(uuidFirstPart) ||
      sanitizedFullContent.includes(AI_RETURN_CODE.NO_NEED_TRANSLATE) ||
      sanitizedFullContent.includes(uuidFirstPart)
    ) {
      const parsed = this.parseNoNeedTranslateResponse(rawAssistantContent + rawReasoningContent);
      if (parsed.hasReason) {
        logMessage(
          `ğŸ”„ AI indicated no translation needed for this file. Reason: ${parsed.reason}`
        );
      } else {
        logMessage(
          `ğŸ”„ AI indicated no translation needed for this file, skipping translation`
        );
      }
      return [AI_RETURN_CODE.NO_NEED_TRANSLATE, originalContent];
    }

    return [AI_RETURN_CODE.OK, sanitizedFullContent];
  }

  private async handleRpmLimit(
    currentVendorName: string,
    rpm: number,
    cancellationToken?: vscode.CancellationToken
  ): Promise<void> {
    const lastRequestTime = vendorLastRequest.get(currentVendorName) || 0;
    const now = Date.now();
    const minInterval = (60 * 1000) / rpm;
    const timeToWait = Math.max(0, minInterval - (now - lastRequestTime));

    if (timeToWait > 0) {
      logMessage(
        `â³ Waiting for API rate limit... (${(timeToWait / 1000).toFixed(
          1
        )} seconds)`
      );

      const waitInterval = 500;
      let waitedTime = 0;
      while (waitedTime < timeToWait) {
        if (cancellationToken?.isCancellationRequested) {
          logMessage(
            "â›” Cancel request detected, stopping API rate limit wait"
          );
          throw new vscode.CancellationError();
        }
        await new Promise((resolve) =>
          globalThis.setTimeout(
            resolve,
            Math.min(waitInterval, timeToWait - waitedTime)
          )
        );
        waitedTime += waitInterval;
      }
    }
  }

  public getTokenCounts() {
    return {
      inputTokens: this.projectTotalInputTokens,
      outputTokens: this.projectTotalOutputTokens,
      totalTokens: this.projectTotalInputTokens + this.projectTotalOutputTokens,
    };
  }

  public resetTokenCounts() {
    this.projectTotalInputTokens = 0;
    this.projectTotalOutputTokens = 0;
  }




}
